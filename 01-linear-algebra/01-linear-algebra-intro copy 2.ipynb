{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c9d0a4",
   "metadata": {},
   "source": [
    "# Objects in Linear Algebra\n",
    "\n",
    "Commonly encountered objects and calculations in Linear Algebra, implemented in Python.\n",
    "\n",
    "Sources:\n",
    "- [Python Numerical Methods: Basics of Linear Algebra](https://pythonnumericalmethods.berkeley.edu/notebooks/chapter14.01-Basics-of-Linear-Algebra.html)\n",
    "- https://en.wikipedia.org/wiki/Matrix_multiplication\n",
    "- https://en.wikipedia.org/wiki/Dot_product\n",
    "- https://en.wikipedia.org/wiki/Cross_product\n",
    "- https://en.wikipedia.org/wiki/Hadamard_product_(matrices)\n",
    "- https://en.wikipedia.org/wiki/Tensor_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b027391d",
   "metadata": {},
   "source": [
    "## 0. Key Takeaways:\n",
    "\n",
    "### 0.1. Syntax \n",
    "\n",
    "- To define vectors and matrices in NumPy, use `np.array([[]])` with double square brackets\n",
    "    - A row vector: `[[ csv row elements ]]`\n",
    "    - A column vector: `[[elem 1], [elem 2], elem 3]]`, and you can put each on a new line\n",
    "    - A matrix: ``[[ csv row 1], [ csv row 2], ...]``, and you can put each on a new line\n",
    "\n",
    "### 0.2. Concepts covered\n",
    "- Basics set notation\n",
    "- Vectors \n",
    "    - Definition and properties (transpose, length `norm`s)\n",
    "    - Addition\n",
    "    - Multiplication (scalar, dot, and cross product)\n",
    "    - Angle between 2 vectors (via dot product)\n",
    "- Matrices\n",
    "    - <mark>A matrix is simply an object which transforms space linearly</mark>\n",
    "    - Definition and properties (transpose, length `norm`s)\n",
    "    - Addition and scalar multiplication\n",
    "    - Matrix multiplication (using `np.dot`) - inner dimensions must match\n",
    "        - *NB: A vector is just a matrix with 1 column (or row if it's a row vector)*\n",
    "    - Square matrices\n",
    "        - **Determinant**\n",
    "        - May be **invertible** (if $AA^{-1}=I)$:\n",
    "            - **Singular** (non-invertible) matrix if $det(A) = 0$\n",
    "                - Ill-conditioned if determinant is *close to 0* (**high** condition number = **more** singular)\n",
    "            - **Non-singular** (invertible) matrix if $det(A) \\ne 0$\n",
    "        - **Rank**: the number of linearly independent columns in the matrix)\n",
    "        - **Trace**: the sum of on-diagonal elements\n",
    "        - Identity Matrix\n",
    "        - Augmented matrix (concatenating a vector $y$ to a matrix $A$ to give $[A,y]$)\n",
    "\n",
    "\n",
    "## List of functions left to write\n",
    "\n",
    "- Masks (e.g. lower triangle, upper triangle and identity)\n",
    "- Basic identities (e.g. LU decomposition and the other commonly used ones, $Z^TZ$ etc, $A^TAI$)\n",
    "\n",
    "## Open questions:\n",
    "- What is the interpretation, and general point of determinant, trace and rank?\n",
    "- Why do we care about full-rank? Is it somehow better?\n",
    "- $\\text{det}(M_1 M_2) = \\text{det}(M_1) \\text{det}(M_2)$\n",
    "- Explain the geometric intuition behind a determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcffab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # more basic functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe396301",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Set Notation\n",
    "\n",
    "- A collection of objects (objects are denoted in braces {})\n",
    "    - **Empty set** (denoted $\\{\\}$ or $\\emptyset$): the set containing no objects)\n",
    "- Common set operations:\n",
    "    - **Union**, $A \\cup B$: Set containing all elements of $A$ **or** $B$\n",
    "    - **Intersection**, $A \\cap B$: Set containing all elements that belong to **both** $A$ **and** $B$\n",
    "    - **Proper/strict subset**, $C \\subset A$: $C$ is a strict subset of (i.e. included in; **but is not equal** to) $A$\n",
    "        - **Subset**, $C\\subseteq A$: $C$ is a subset of (i.e. included in; **or is equal** to) $A$\n",
    "    - **Proper/strict superset**, $C \\supset A$: $C$ is a strict superset of (i.e. includes; **but is not equal** to) $A$\n",
    "        - **Superset**, $C\\supseteq A$: $C$ is a superset of (i.e. includes; **or is equal** to) $A$\n",
    "    - **Relative complement**: \n",
    "    - Colon ($:$) means \"**such that**\"\n",
    "    - $a\\in A$ means \"element $a$ is a member of set $A$\"\n",
    "    - Backslash ($\\backslash$) means \"\"**set minus**\" so if $a\\in A$, then  $A\\backslash a$ means \"$A$ minus the element $a$\"\n",
    "- Some standard sets related to numbers: \n",
    "    - Naturals: $\\mathbb{N} = \\{1, 2, 3, 4, \\cdots\\}$\n",
    "    - Wholes: $\\mathbb{W} = \\mathbb{N} \\cup \\{0\\}$\n",
    "    - Integers: $\\mathbb{Z} = \\mathbb{W} \\cup \\{-1, -2, -3, \\cdots\\}$\n",
    "    - Rationals: $\\mathbb{Q} =  \\{\\frac{p}{q} : p\\in {\\mathbb{Z}}, q\\in {\\mathbb{Z}} \\backslash \\{0\\}\\}$\n",
    "    - Irrationals: $\\mathbb{I}$ is the set of real numbers not expressible as a fraction of integers\n",
    "    - Reals: $\\mathbb{R} = \\mathbb{Q} \\cup \\mathbb{I}$\n",
    "    - Complex numbers: $\\mathbb{C} = \\{a + bi : a,b\\in {\\mathbb{R}}, i = \\sqrt{-1}\\}$\n",
    "- Example:\n",
    "    - Let $S$ be the set of all real $(x,y)$ pairs such that $x^2 + y^2 = 1$ Write $S$ using set notation:\n",
    "    - $S = \\{(x,y) : x,y \\in {\\mathbb{R}}, x^2 + y^2 = 1\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f0c401",
   "metadata": {},
   "source": [
    "## 2. Vectors\n",
    "\n",
    "### Properties of a vector $\\mathbf{v}$:\n",
    "- $i$'th element: $v_i$\n",
    "- Transpose (turns columns into rows and vice versa): $\\mathbf{v}^\\mathrm{T}$ (for a matrix it swaps rows with columns)\n",
    "    - By convention, vectors are implicitly column vectors. Hence, to represent $\\mathbf{v}$ as a row vector, we denote its transposed form: $\\mathbf{v}^\\mathrm{T}$.\n",
    "- Length (many definitions (distance formulas) we can use):\n",
    "    - $L_2$ norm (Euclidian length): $\\Vert\\mathbf{v}\\Vert_2 = \\sqrt{\\Sigma_i v_{i}^{2}}\\quad$ (*physical length* of a vector in n-dim space)\n",
    "    - $L_1$ norm (Manhattan Distance): $\\Vert\\mathbf{v}\\Vert_1 = \\Sigma_i |v_i|\\quad $\n",
    "    - More generally, \n",
    "        - The **p-norm** is $\\Vert v \\Vert_{p} = \\sqrt[p]{(\\sum_i v_i^p)}$\n",
    "        - And the $L_\\infty$ norm, $\\Vert\\mathbf{v}\\Vert_\\infty$, is the $p$-norm where $p=\\infty$\n",
    "- Generally the $L_2$ norm is implied when referring to vector length. \n",
    "  - Hence $\\Vert\\mathbf{v}\\Vert_2$ can be written more simply as $\\Vert\\mathbf{v}\\Vert$ or occasionally $|\\mathbf{v}|$ (though the latter is ambiguous with the absolute value of a scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bc245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -5  3  2  4]\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "(1, 5)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create a row vector and a column vector, show their shapes\n",
    "row_vec = np.array([[1, -5, 3, 2, 4]])\n",
    "col_vec = np.array([[1], [2], [3], [4]])\n",
    "\n",
    "# Comments show output if you don't use list of lists\n",
    "print(row_vec[0])  # [ 1 -5  3  2  4]\n",
    "print(col_vec)  # [1 2 3 4]\n",
    "print(row_vec.shape)  # (5,)\n",
    "print(col_vec.shape)  # (4,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b209b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1]\n",
      " [-5]\n",
      " [ 3]\n",
      " [ 2]\n",
      " [ 4]]\n",
      "L_1 is: 15.0\n",
      "L_2 is: 7.4\n",
      "L_inf is: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Transpose row_vec and calculate L1, L2, and L_inf norms\n",
    "from numpy.linalg import norm\n",
    "\n",
    "transposed_row_vec = row_vec.T  # now a column vector\n",
    "print(transposed_row_vec)\n",
    "\n",
    "norm_1 = norm(transposed_row_vec, 1)\n",
    "norm_2 = norm(transposed_row_vec, 2)  # <- L2 norm is default and most common\n",
    "norm_inf = norm(transposed_row_vec, np.inf)\n",
    "\n",
    "print(f\"L_1 is: {norm_1:.1f}\")\n",
    "print(f\"L_2 is: {norm_2:.1f}\")\n",
    "print(f\"L_inf is: {norm_inf:.1f}\")  # NB: norm_inf = |largest element|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9d66e",
   "metadata": {},
   "source": [
    "## 3. Vector addition, $\\mathbf{v} + \\mathbf{w}$\n",
    "\n",
    "Elementwise addition; if vectors are of of same length (i.e. if $\\mathbf{v}$ and $\\mathbf{w}$ are both in $\\mathbb{R}^n$) then:\n",
    "\n",
    "- **Addition of 2 vectors**: $\\mathbf{u} = \\mathbf{v} + \\mathbf{w}$ is the vector with elements $u_i = v_i + w_i$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43707e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector addition: \n",
      "v + w = [12 14 15]\n"
     ]
    }
   ],
   "source": [
    "# Sum vectors v = [10, 9, 3] and w = [2, 5, 12]\n",
    "v = np.array([[10, 9, 3]])\n",
    "w = np.array([[2, 5, 12]])\n",
    "u = v + w\n",
    "\n",
    "print(\"Vector addition: \\nv + w =\", u[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07b497",
   "metadata": {},
   "source": [
    "## 4. Scalar-vector multiplication, $\\alpha\\mathbf{v}$\n",
    "\n",
    "To multiply a vector $\\mathbf{v}$, by a scalar $\\alpha$ (a number in $\\mathbb{R}$), do it \"elementwise\" or \"pairwise\".\n",
    "\n",
    "- **Scalar multiplication of a vector**: $\\mathbf{u} = \\alpha \\mathbf{v}$ is the vector with elements $u_i = \\alpha v_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623eb32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar vector multiplication: \n",
      "alpha * v = [40 36 12]\n"
     ]
    }
   ],
   "source": [
    "# Multiply vector v = [10, 9, 3] by scalar alpha = 4\n",
    "v = np.array([[10, 9, 3]])\n",
    "alpha = 4\n",
    "u = alpha * v\n",
    "\n",
    "print(\"Scalar vector multiplication: \\nalpha * v =\", u[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1095e71b",
   "metadata": {},
   "source": [
    "### 4.1. Linear Combinations\n",
    "\n",
    "- A **linear combination** of set $S$ is defined as $\\Sigma \\alpha_i s_i$\n",
    "    - Here $\\alpha_i$ values are the **coefficients** of $s_i$ values\n",
    "    - Example: Grocery bill total cost is a linear combination of items purchased:\n",
    "        - $\\displaystyle{\\sum c_i n_i}$ ($c_i$ is item cost, $n_i$ is qty. purchased)\n",
    "    \n",
    "### 4.2. Linear Dependence and Independence\n",
    "    \n",
    "- A set is **linearly INdependent** if no object in the set can be written as a lin. combination of the other objects in the set.\n",
    "    - Example: $\\mathbf{v} = [1, 1, 0], \\mathbf{w} = [1, 0, 0]$ and $\\mathbf{u} = [0, 0, 1]$ are <mark>linearly independent. Can you see why?</mark>\n",
    "- Below is an example of a **linearly DEpendent** set. $\\mathbf{x}$ is dependent on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20147719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is a linear combination of v, w, and u. It is linearly dependent on them: \n",
      "x = [-8 -1  4]\n"
     ]
    }
   ],
   "source": [
    "# Writing the vector x = [-8, -1, 4] as a linear combination of 3 vectors, v, w, and u:\n",
    "v = np.array([[0, 3, 2]])\n",
    "w = np.array([[4, 1, 1]])\n",
    "u = np.array([[0, -2, 0]])\n",
    "\n",
    "x = 3 * v - 2 * w + 4 * u\n",
    "print(\"x is a linear combination of v, w, and u. It is linearly dependent on them: \\nx =\", x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2fa7eb",
   "metadata": {},
   "source": [
    "## 5. Vector-vector multiplication (3 approaches)\n",
    "\n",
    "### 5.1. Vector dot product, $\\mathbf{v} \\cdot \\mathbf{w}$ (i.e. commonly \"vector times vector\")\n",
    "\n",
    "Geometric interpretation: <mark>A measure of how similarly directed two vectors are</mark>\n",
    "\n",
    "- Definition: $\\mathbf{v} \\cdot \\mathbf{w} = \\Sigma_{i=1}^n v_i w_i$\n",
    "    - It's the sum of elementwise products. For $\\mathbf{v}, \\mathbf{w} \\in \\mathbb{R}^n$, \n",
    "- Note also, since $\\mathbf{v}, \\mathbf{w} \\in \\mathbb{R}^n$, transpose to make inner dimensions match. Dot product can hence be rewritten as:\n",
    "    - $\\mathbf{v} \\cdot \\mathbf{w} = \\mathbf{v}^\\mathrm{T}\\mathbf{w}$\n",
    "\n",
    "#### Angle between vectors, $\\theta$\n",
    "\n",
    "- Think of dot product as \"**degree of alignment**\": $\\mathbf{v} \\cdot \\mathbf{w} = \\Vert\\mathbf{v}\\Vert\\:\\Vert\\mathbf{w}\\Vert \\cos \\theta$\n",
    "    - (1,1) and (2,2) are **parallel**; computing the angle gives $\\theta = 0$\n",
    "    - (1,1) and (-1,1) are **orthogonal** (perpendicular) bc $\\theta = \\pi/2$ and $\\mathbf{v} \\cdot \\mathbf{w} = 0$ (no alignment)\n",
    "\n",
    "* Extending on the dot product idea, $\\mathbf{v} \\cdot \\mathbf{w}$, the **angle between two vectors** is $\\theta$. It is as defined by the formula:\n",
    "$$ \\theta = \\arccos \\left({\\frac {\\mathbf{v} \\cdot \\mathbf{w}}{\\left\\|\\mathbf{v}\\right\\|\\left\\|\\mathbf{w} \\right\\|}}\\right) $$\n",
    "\n",
    "#### Recap: Many ways to express a dot product (it's commutative!):\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\n",
    "\\mathbf{v} \\cdot \\mathbf{w} = \\Sigma_{i=1}^n v_i w_i &= \\mathbf{v}^\\mathrm{T}\\mathbf{w} = \\Vert\\mathbf{v}\\Vert\\:\\Vert\\mathbf{w}\\Vert \\cos \\theta \\\\\n",
    "& = \\mathbf{w}^\\mathrm{T}\\mathbf{v} = \\Vert\\mathbf{w}\\Vert\\:\\Vert\\mathbf{v} \\Vert \\cos \\theta = \\mathbf{w} \\cdot \\mathbf{v}\n",
    "\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f895c678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector dot product: v • w = 101\n",
      "Theta = 0.979924710443726\n"
     ]
    }
   ],
   "source": [
    "from numpy import arccos, dot\n",
    "\n",
    "# Compute the dot product of vectors v = [10, 9, 3] and w = [2, 5, 12]\n",
    "v = np.array([[10, 9, 3]])\n",
    "w = np.array([[2, 5, 12]])\n",
    "u = dot(v, w.T)  # w.T to match inner dims\n",
    "print(\"Vector dot product: v • w =\", u[0][0])\n",
    "\n",
    "# Compute the angle between vectors v and w\n",
    "theta = arccos(u / (norm(v) * norm(w)))  # w.T to match inner dims, norm() default is L2\n",
    "print(\"Theta =\", theta[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4beca",
   "metadata": {},
   "source": [
    "### 5.2. Vector Hadamard (element-wise) product, $\\mathbf{v}\\odot \\mathbf{w}$:\n",
    "\n",
    "- Definition: Element-wise product, where the vectors **must be of the same dimension**\n",
    "    - This method also works for matrices of the same dimension.\n",
    "    - Output vector/matrix is of the same dimension as the operands.\n",
    "- Notation: $\\mathbf{v}\\odot \\mathbf{w}$ (sometimes $\\mathbf{v}\\circ \\mathbf{w}$)\n",
    "    - Elements of the resultant vector are given by: $ (\\mathbf{v}\\odot \\mathbf{w})_{i} = (\\mathbf{v})_{i}(\\mathbf{w})_{i} $\n",
    "- Example:\n",
    "\n",
    "\\begin{bmatrix}2&3&1\\end{bmatrix} \\odot {\\begin{bmatrix}3&1&4\\end{bmatrix}}={\\begin{bmatrix}2\\times 3&3\\times 1&1\\times 4\\end{bmatrix}}={\\begin{bmatrix}6&3&4\\end{bmatrix}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b7313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Hadamard product:\n",
      "v ⊙ w = [6 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Compute the Hadamard product of vectors v = [2, 3, 1] and w = [3, 1, 4]\n",
    "v = np.array([[2, 3, 1]])\n",
    "w = np.array([[3, 1, 4]])\n",
    "u = np.multiply(v, w)\n",
    "\n",
    "print(\"Vector Hadamard product:\\nv ⊙ w =\", u[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6fca0",
   "metadata": {},
   "source": [
    "### 5.3. Vector cross product, $\\mathbf{v}\\times \\mathbf{w}$\n",
    "\n",
    "Geometric interpretation: The cross product $\\mathbf{v} \\times \\mathbf{w}$ is <mark>a vector perpendicular to both</mark> $\\mathbf{v}$ <mark>and</mark> $\\mathbf{w}$, <mark>whose length equals the area enclosed by the parallelogram created by the two vectors</mark>\n",
    "\n",
    "- Cross product definition: \n",
    "$$\\mathbf{v} \\times \\mathbf{w} = \\Vert \\mathbf{v} \\Vert \\: \\Vert \\mathbf{w} \\Vert\\sin{(\\theta)} \\, \\mathbf{n}$$\n",
    "- Where: \n",
    "    - $\\theta$ can by computed via dot product\n",
    "    - $\\mathbf{n}$ is a unit vector (i.e. length $1$) perpendicular to both $\\mathbf{v}$ and $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab5b4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector cross product:\n",
      "v ⨉ w = [ 0  0 -6]\n"
     ]
    }
   ],
   "source": [
    "# Compute the cross product of v = [0,2,0] and w = [3,0,0]\n",
    "v = np.array([[0, 2, 0]])\n",
    "w = np.array([[3, 0, 0]])\n",
    "u = np.cross(v, w)\n",
    "\n",
    "print(\"Vector cross product:\\nv ⨉ w =\", u[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c36c9",
   "metadata": {},
   "source": [
    "## 6. Matrices\n",
    "\n",
    "These are $\\mathbb{R}^{m\\times n}$ objects.\n",
    "\n",
    "### 6.1. <mark>Geometric intuition (from 3B1B)</mark>:\n",
    "- <mark>Think of matrices as **encoding** linear transformations of vector spaces</mark>\n",
    "    - I.e. A matrix $\\mathbf{A}$ moves **every input vector** (more precisely, the **point where every vector's tip is**) **linearly** to a new location.\n",
    "- The columns of the matrix can be thought of as **landing points** for the basis (unit) vectors $\\hat{i}$ and $\\hat{j}$ after the transformation is applied\n",
    "- A linear transformation means after applying the matrix $\\mathbf{A}$:\n",
    "    - **the origin remains fixed**, and \n",
    "    - **all grid lines in the space remain straight, parallel, and evenly spaced**\n",
    "\n",
    "### 6.2. Length: \n",
    "\n",
    "If you treat the $m \\times n$ elements of $\\mathbf{M}$ as an $mn$-dimensional (flattened 2D to 1D) **\"vector\"**, the $p$-norm of that \"vector\" is:\n",
    "\n",
    "$$\\Vert \\mathbf{M} \\Vert_{p} = \\sqrt[p]{(\\sum_i^m \\sum_j^n |m_{ij}|^p)}$$\n",
    "\n",
    "For a matrix we also commonly use the L2 norm (referred to as the ***Frobenius norm***) to calculate its magnitude vector. Substitute $p=2$ above\n",
    "\n",
    "## 7. Matrix addition, $\\mathbf{A} + \\mathbf{B}$\n",
    "\n",
    "Same mechanics as for vectors (see above)\n",
    "* **Matrix addition**: $\\mathbf{M} = \\mathbf{A} + \\mathbf{B}$ is the matrix with elements $M_{ij} = A_{ij} + B_{ij}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6292f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix addition: \n",
      "A + B =\n",
      " [[ 4  8]\n",
      " [ 6 10]\n",
      " [14  5]]\n"
     ]
    }
   ],
   "source": [
    "# Sum matrices A and B:\n",
    "A = np.array([[1, 7], [2, 3], [5, 0]])\n",
    "B = np.array([[3, 1], [4, 7], [9, 5]])\n",
    "M = A + B\n",
    "\n",
    "print(\"Matrix addition: \\nA + B =\\n\", M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af23659",
   "metadata": {},
   "source": [
    "## 8. Scalar-matrix multiplication, $\\alpha\\mathbf{A}$\n",
    "* **Scalar multiplication of a matrix**: $\\mathbf{M} = \\alpha \\mathbf{A}$ is the matrix with elements $M_{ij} = \\alpha A_{ij}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "941d3b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar matrix multiplication: \n",
      "alpha * A =\n",
      " [[ 2 14]\n",
      " [ 4  6]\n",
      " [10  0]]\n"
     ]
    }
   ],
   "source": [
    "# Multiply matrix A by scalar value alpha = 2\n",
    "A = np.array([[1, 7], [2, 3], [5, 0]])\n",
    "alpha = 2\n",
    "M = alpha * A\n",
    "\n",
    "print(\"Scalar matrix multiplication: \\nalpha * A =\\n\", M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45386034",
   "metadata": {},
   "source": [
    "## 9. Matrix multiplication (4 approaches)\n",
    "### 9.1. Matrix times vector multiplication $\\mathbf{Av}$ (<mark>important</mark>)\n",
    "\n",
    "<mark>Geometric intuition (3B1B)</mark>:\n",
    "- A matrix $\\mathbf{A}$ represents a <mark>linear transformation of a vector space</mark> (where $\\mathbf{A} \\isin \\mathbb{R}^{m \\times n}$).\n",
    "- Matrix-vector multiplication $\\mathbf{v_{new}=Av}$ <mark>applies this transformation</mark> (encoded in $\\mathbf{A}$) <mark>to a column vector</mark> $\\mathbf{v}$ (where $\\mathbf{v} \\isin \\mathbb{R}^{n \\times 1}$).\n",
    "    - Note how inner dimensions match: $\\mathbf{A} \\isin \\mathbb{R}^{m \\times n}$ and $\\mathbf{v} \\isin \\mathbb{R}^{n \\times 1}$, therefore the result $\\mathbf{v_{new}}$ will also be a column vector, albeit in $\\mathbb{R}^{m \\times 1}$.\n",
    "- Elements of the resultant vector (let's call it $\\mathbf{y=v_{new}}$) are given by: $$ y_i = \\sum _{j=1}^{n}a_{ij}v_{j} $$\n",
    "- <mark>**3B1B intuition for square matrices**</mark>: \n",
    "    - The new vector $\\mathbf{v_{new}}$ will be a linear combination of the columns of $\\mathbf{A}$ (i.e. where the basis vectors $\\hat{i}$ and $\\hat{j}$ **end up** in the new space)\n",
    "    - with coefficients given by the elements of $\\mathbf{v}$.\n",
    "    - For non-square matrices see [this link](https://math.stackexchange.com/questions/1988948/geometric-interpretation-of-non-square-matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0839d2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix vector multiplication: \n",
      "Av =\n",
      " [[23]\n",
      " [13]\n",
      " [10]]\n"
     ]
    }
   ],
   "source": [
    "# Multiply matrix A by (column) vector v = [2, 3]\n",
    "A = np.array([[1, 7], [2, 3], [5, 0]])\n",
    "v = np.array([[2], [3]])  # column vector\n",
    "M = A @ v\n",
    "\n",
    "print(\"Matrix vector multiplication: \\nAv =\\n\", M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e12ac",
   "metadata": {},
   "source": [
    "### 9.2. Vector times matrix multiplication, $\\mathbf{v}^\\mathrm{T}\\mathbf{A}$\n",
    "- To multiply a (column) vector by a matrix, first transpose the vector $\\mathbf{v}$ (i.e. make it a **row** vector $\\mathbf{v}^\\mathbf{T}$) to make the inner dimensions match.\n",
    "    - Note how in $\\mathbf{v_{new}=v}^\\mathrm{T}\\mathbf{A}$, inner dimensions match: $\\mathbf{v}^\\mathrm{T} \\isin \\mathbb{R}^{1 \\times m}$, and $\\mathbf{A} \\isin \\mathbb{R}^{m \\times n}$ therefore the result $\\mathbf{v_{new}}$ will also be a row vector in $\\mathbb{R}^{1 \\times n}$.\n",
    "- Elements of the resultant vector (let's call it $\\mathbf{y=v_{new}}$) are given by: $$y_{k}=\\sum _{j=1}^{n}v_{j}a_{jk}$$\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f8dd15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector matrix multiplication: \n",
      "v^T A = [13 23]\n"
     ]
    }
   ],
   "source": [
    "# Transpose the column vector v = [2, 3, 1], and multiply the resulting row vector v^T by matrix A\n",
    "v = np.array([[2], [3], [1]])  # column vector\n",
    "A = np.array([[1, 7], [2, 3], [5, 0]])\n",
    "M = v.T @ A  # v.T is a row vector\n",
    "\n",
    "print(\"Vector matrix multiplication: \\nv^T A =\", M[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c996eb",
   "metadata": {},
   "source": [
    "### 9.3. Matrix times matrix Hadamard (element-wise) product, $A\\odot B$:\n",
    "\n",
    "- Definition (same as for vectors): Element-wise product on two matrices of same-dimension (i.e. $A, B\\isin \\mathbb{R}^{m \\times n}$)\n",
    "- Elements of the resultant matrix are given by: $ (A\\odot B)_{ij} = (A)_{ij}(B)_{ij} $. Example:\n",
    "\n",
    "\\begin{bmatrix}2&3&1\\\\0&8&-2\\end{bmatrix} \\odot {\\begin{bmatrix}3&1&4\\\\7&9&5\\end{bmatrix}}={\\begin{bmatrix}2\\times 3&3\\times 1&1\\times 4\\\\0\\times 7&8\\times 9&-2\\times 5\\end{bmatrix}}={\\begin{bmatrix}6&3&4\\\\0&72&-10\\end{bmatrix}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d408dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Hadamard product: \n",
      "A ⊙ B =\n",
      " [[  6   3   4]\n",
      " [  0  72 -10]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the Hadamard product of matrices A and B:\n",
    "A = np.array([[2, 3, 1], [0, 8, -2]])\n",
    "B = np.array([[3, 1, 4], [7, 9, 5]])\n",
    "M = np.multiply(A, B)\n",
    "\n",
    "print(\"Matrix Hadamard product: \\nA ⊙ B =\\n\", M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e37403",
   "metadata": {},
   "source": [
    "### 9.4. Matrix times matrix multiplication, $\\mathbf{AB}$ (use `np.dot(A,B)` to multiply)\n",
    "\n",
    "The inner matrix dimensions of the two matrices (e.g. $\\mathbf{A}$ and $\\mathbf{B}$) **must match**. \n",
    "- $\\mathbf{A}$ is of dimension $\\mathbb{R}^{m \\times p}$\n",
    "- $\\mathbf{B}$ is of dimension $\\mathbb{R}^{p \\times n}$ \n",
    "- Here, the dimension of size $p$ is the **inner matrix dimension**. \n",
    "    - If they match, it means # columns in $\\mathbf{A}$ equals # rows in $\\mathbf{B}$.\n",
    "- Dimensions $m$ and $n$ are the **outer matrix dimensions**. Thus each element of $\\mathbf{M=AB}$ can be computed as:\n",
    "\n",
    "$$M_{ij} = \\sum_{k=1}^p P_{ik}Q_{kj}$$\n",
    "\n",
    "- <mark>I.e. (important)</mark> the $i,j$'th element of $\\mathbf{M}$ is the dot product of the $i$'th row of $\\mathbf{A}$ with $j$'th column of $\\mathbf{Q}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3e5910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[1 7]\n",
      " [2 3]\n",
      " [5 0]]\n",
      "\n",
      "B =\n",
      " [[2 6 3 1]\n",
      " [1 2 3 4]]\n",
      "\n",
      "AB =\n",
      " [[ 9 20 24 29]\n",
      " [ 7 18 15 14]\n",
      " [10 30 15  5]]\n"
     ]
    }
   ],
   "source": [
    "# Multiply A=[[1,7],[2,3],[5,0]] and B=[[2,6,3,1],[1,2,3,4]] -> [3x2] * [2x4] = output [3x4]\n",
    "\n",
    "A = np.array([[1, 7], [2, 3], [5, 0]])\n",
    "B = np.array([[2, 6, 3, 1], [1, 2, 3, 4]])\n",
    "print(\"A =\\n\", A)\n",
    "print(\"\\nB =\\n\", B)\n",
    "print(\"\\nAB =\\n\", np.dot(A, B))  # <-- inner dimensions match (p=2). output is a [3x4] matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0ebefb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,4) and (3,2) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Multiplying B and A will raise a ValueError\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# <-- inner dimensions don't match ...4] * [3...; Error\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,4) and (3,2) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Multiplying B and A will raise a ValueError\n",
    "np.dot(B, A)  # <-- inner dimensions don't match ...4] * [3...; Error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd7d98",
   "metadata": {},
   "source": [
    "## 7. Square matrices\n",
    "\n",
    "Square matrices have dimension $n \\times n$, i.e. $A \\isin \\mathbb{R}^{n \\times n}$\n",
    "\n",
    "### 7.1. Determinant, $\\text{det}(\\textbf{M})$\n",
    "- The **Determinant**, $det(\\textbf{M})$, is an important property of square matrices.\n",
    "- <mark>**Geometric intuition of a determinant**</mark> (From 3B1B):\n",
    "    - Its absolute value tells you how much an area increases/decreases after the transformation by matrix $\\textbf{M}$\n",
    "    - A **negative sign** tells you whether the vector space was \"flipped\" (i.e. if the basis vectors swapped sides)\n",
    "    - <mark>**If the determinant is 0**</mark>, it means space has dropped **into fewer dimensions**\n",
    "        - i.e. **at least 1 dimension is LOST*, so initial the area, volume, etc of the vector space is now 0\n",
    "        - e.g. if a 2D matrix $\\textbf{M}$ transforms areas into a 1D line (or a point), areas get squished to 0; hence $\\text{det}(\\textbf{M})=0$\n",
    "- To prove understanding, explain: $\\text{det}(\\textbf{M}_1 \\textbf{M}_2) = \\text{det}(\\textbf{M}_1) \\text{det}(\\textbf{M}_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88f0cf-f401-476c-a667-64515ed2ffa5",
   "metadata": {},
   "source": [
    "#### Formulae for calculating the determinant of a matrix $\\textbf{M}$:\n",
    "\n",
    "- For a $2 \\times 2$ matrix; $det(\\textbf{M})$ is:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "|\\textbf{M}| = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\\\\\n",
    "\\end{bmatrix} = ad - bc\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "- For a $3 \\times 3$ matrix; $det(\\textbf{M})$ is:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "% \\begin{eqnarray*}\n",
    "\\begin{align*}\n",
    "|\\textbf{M}| = \\begin{bmatrix}\n",
    "a & b & c \\\\\n",
    "d & e & f \\\\\n",
    "g & h & i \\\\\n",
    "\\end{bmatrix} & = a\\begin{bmatrix}\n",
    "\\Box &\\Box  &\\Box  \\\\\n",
    "\\Box & e & f \\\\\n",
    "\\Box & h & i \\\\\n",
    "\\end{bmatrix} - b\\begin{bmatrix}\n",
    "\\Box &\\Box  &\\Box  \\\\\n",
    "d & \\Box & f \\\\\n",
    "g & \\Box & i \\\\\n",
    "\\end{bmatrix} + c\\begin{bmatrix}\n",
    "\\Box &\\Box  &\\Box  \\\\\n",
    "d & e & \\Box \\\\\n",
    "g & h & \\Box \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&&\\\\\n",
    "& = a\\begin{bmatrix}\n",
    "e & f \\\\\n",
    "h & i \\\\\n",
    "\\end{bmatrix} - b\\begin{bmatrix}\n",
    "d & f \\\\\n",
    "g & i \\\\\n",
    "\\end{bmatrix} + c\\begin{bmatrix}\n",
    "d & e \\\\\n",
    "g & h \\\\\n",
    "\\end{bmatrix} \\\\ \n",
    "&&\\\\\n",
    "& = aei + bfg + cdh - ceg - bdi - afh\n",
    "% \\end{eqnarray*}\n",
    "\\end{align*}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "- For higher dimension matrices, a similar approach can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab918b-c509-45f1-b813-e8dd1f070548",
   "metadata": {},
   "source": [
    "### 7.2. Identity matrix\n",
    "\n",
    "- A square matrix, $\\textbf{I}$, with **ones on the diagonal** and **zeros everywhere else**\n",
    "- Multiplying a matrix with $\\textbf{I}$ (of compatible dimensionality) will produce the same matrix (like how $n \\times 1 = n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f78ebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M:\n",
      " [[0 2 1 3]\n",
      " [3 2 8 1]\n",
      " [1 0 0 3]\n",
      " [0 3 2 1]]\n",
      "Determinant: -38.0\n",
      "\n",
      "I:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "\n",
      "M*I:\n",
      " [[0. 2. 1. 3.]\n",
      " [3. 2. 8. 1.]\n",
      " [1. 0. 0. 3.]\n",
      " [0. 3. 2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Find the determinant of M, and multiply M by np.eye(4) to show M x I = M\n",
    "\n",
    "from numpy.linalg import det\n",
    "\n",
    "M = np.array([[0, 2, 1, 3], [3, 2, 8, 1], [1, 0, 0, 3], [0, 3, 2, 1]])\n",
    "print(\"M:\\n\", M)\n",
    "\n",
    "print(f\"Determinant: {det(M):.1f}\")\n",
    "I = np.eye(4)\n",
    "print(\"\\nI:\\n\", I)\n",
    "print(\"\\nM*I:\\n\", np.dot(M, I))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4708f",
   "metadata": {},
   "source": [
    "## 8. Matrix inverse\n",
    "\n",
    "For square matrices ($\\mathbb{R}^{n\\times n}$), $\\textbf{M}^{-1}$ is the inverse of $\\textbf{M}$ if $\\textbf{M} \\cdot \\textbf{M}^{-1} = I$ (like how $3 \\times \\frac{1}{3} = 1$)\n",
    "\n",
    "- A matrix is **invertible** if it has an inverse (non-square matrices are **not** invertible)\n",
    "- The inverse of a matrix is unique: An invertible matrix **only has one inverse**.\n",
    "- For a $2 \\times 2$ matrix, the inverse is:\n",
    "$$\n",
    "\\begin{split}\n",
    "\\textbf{M}^{-1} = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\\\\\n",
    "\\end{bmatrix}^{-1} = \\frac{1}{|\\textbf{M}|}\\begin{bmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\\\\\n",
    "\\end{bmatrix}\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "### 8.1. Is it invertible?\n",
    "\n",
    "- **Singular matrices** are those which have **no inverses** (like how 0 has no inverse)\n",
    "    - $det(\\textbf{M}) = 0$\n",
    "- **Nonsingular matrices** are those which **do have an inverse**\n",
    "    - $det(\\textbf{M}) \\ne 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30704487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall, M has non-zero determinant so is invertible; but det(P)=0 so it can't be inverted\n",
    "\n",
    "from numpy.linalg import inv\n",
    "\n",
    "print(f\"Determinant: {det(M):.1f}\")\n",
    "print(\"Inv M:\\n\", inv(M))\n",
    "\n",
    "P = np.array([[0, 1, 0], [0, 0, 0], [1, 0, 1]])\n",
    "print(\"det(p):\", det(P))\n",
    "print(\"Inv P:\\n\", inv(P))  # <-- Error thrown because P is Singular (non-invertible)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdcdcb1",
   "metadata": {},
   "source": [
    "### 8.2. Ill-Conditioned Matrices\n",
    "\n",
    "- An ill-conditioned matrix is one which is **close to being singular** \n",
    "    - Its determinant will be close to 0 (problematic in the same way dividing by a tiny number is)\n",
    "    - Computation errors (overflow, underflow, round-off errors) may occur\n",
    "- **Condition number**: ***Higher number*** means the matrix is ***more*** ill-conditioned (i.e. closer to being singular)\n",
    "\n",
    "### 8.3. Trace \n",
    "\n",
    "- The **trace** of $\\textbf{A} : \\textbf{A} \\in \\mathbb{R}^{n\\times n}$ is the sum of elements on the main diagonal (from left to right):\n",
    "\n",
    "$$ \\text{tr}(\\textbf{A}) = \\sum_{i=1}^{n} a_{ii} $$\n",
    "\n",
    "\n",
    "## 9. Back to non-square matrices\n",
    "\n",
    "### 9.1. Rank\n",
    "\n",
    "- The **rank** of $\\textbf{A} : \\textbf{A} \\in \\mathbb{R}^{m\\times n}$ is the **number of linearly independent columns or rows** in $\\textbf{A}$\n",
    "    - NB: Num. of lin. indep. cols. in a matrix $\\equiv$ Num. of lin. indep. rows in that matrix\n",
    "\n",
    "#### 9.1.1. \"Full Rank\" Matrix\n",
    "\n",
    "- $\\textbf{A}$ is **full rank** if $\\text{rank}(\\textbf{A}) = \\min(m,n)$\n",
    "- $\\textbf{A}$ is also full rank if **all its columns are linearly independent**\n",
    "\n",
    "#### 9.1.2. Augmented Matrix\n",
    "\n",
    "- If vector $\\textbf{y}$ is concatenated to matrix $\\textbf{A}$, we say \"$\\textbf{A}$ augmented with $\\textbf{y}$\".\n",
    "    - if $\\text{rank}([\\textbf{A},\\textbf{y}]) = \\text{rank}(\\textbf{A})+1$, then vector $\\textbf{y}$ is **\"new\" information**\n",
    "    - otherwise it means $\\textbf{y}$ can be created as a linear combination of the columns in $\\textbf{A}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the condition number and rank for matrix A = [[1,1,0],[0,1,0],[1,0,1]]\n",
    "# If y = [[1],[2],[1]], get the augmented matrix [A,y]\n",
    "\n",
    "from numpy import trace\n",
    "from numpy.linalg import cond, matrix_rank\n",
    "\n",
    "A = np.array([[1, 1, 0], [0, 1, 0], [1, 0, 1]])\n",
    "\n",
    "print(\"Condition number:\", cond(A))\n",
    "print(\"Rank:\", matrix_rank(A))\n",
    "print(\"Trace:\", trace(A))\n",
    "y = np.array([[1], [2], [1]])\n",
    "print(\"A matrix's shape:\", A.shape, \"\\ny vector's shape\", y.shape)\n",
    "A_y = np.concatenate((A, y), axis=1)\n",
    "print(\"Augmented matrix:\\n\", A_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c39f4-4521-40fd-bc32-5935bfe78287",
   "metadata": {},
   "source": [
    "# 10. 3Blue1Brown's aside\n",
    "## A few useful transformations\n",
    "\n",
    "### Vector Transformations\n",
    "\n",
    "### Matrix Transformations (TBC double check)\n",
    "\n",
    "$$ \\begin{align*} \n",
    "\\text{No change (Identity matrix)} &: \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} &\\text{in 3D:} \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Translation} &: \\text{NA} &\\text{in 3D:} \\begin{bmatrix} 1 & 0 & X \\\\ 0 & 1 & Y \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Scaling (about origin)} &: \\begin{bmatrix} W & 0 \\\\ 0 & H \\end{bmatrix} &\\text{in 3D:} \\begin{bmatrix} W & 0 & 0 \\\\ 0 & H & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Rotation (about origin)} &: \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix} &\\text{in 3D:} \\begin{bmatrix} \\cos\\theta & -\\sin\\theta & 0 \\\\ \\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Shear (in x-direction)} &: \\begin{bmatrix} 1 & \\tan\\phi \\\\ 0 & 1 \\end{bmatrix} &\\text{in 3D:} \\begin{bmatrix} 1 & \\tan\\phi & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Shear (in y-direction)} &: \\begin{bmatrix} 1 & 0 \\\\ \\tan\\psi & 1 \\end{bmatrix} &\\text{in 3D:}\\begin{bmatrix} 1 & 0 & 0 \\\\ \\tan\\psi & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Reflect (about origin)} &: \\begin{bmatrix} -1 & 0 \\\\ 0 & -1 \\end{bmatrix} &\\text{in 3D:} \\begin{bmatrix} -1 & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Reflect (about x-axis)} &: \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} &\\text{in 3D:} \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\text{Reflect (about y-axis)} &: \\begin{bmatrix} -1 & 0 \\\\ 0 & 1 \\end{bmatrix} &\\text{in 3D:} \\begin{bmatrix} -1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\\\\\\\\n",
    "\\end{align*} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
