{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c9d0a4",
   "metadata": {},
   "source": [
    "# Linear Algebra - Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f0c401",
   "metadata": {},
   "source": [
    "## 1. Vectors\n",
    "\n",
    "### Notation:\n",
    "- A vector, $\\textbf{v}$, is a list of numbers (scalars) arranged in a particular order.\n",
    "- By convention, vectors are implicitly **column vectors**. So $\\textbf{v} \\in \\mathbb{R}^{n}$; or implicitly $\\textbf{v} \\in \\mathbb{R}^{n \\times 1}$.\n",
    "- To represent a column vector, $\\textbf{v}$, as a **row vector**, take its **transpose** $\\textbf{v}^\\mathrm{T}$. Hence, $\\textbf{v}^\\mathrm{T} \\in \\mathbb{R}^{1 \\times n}$.\n",
    "    - **Transpose** operation turns a column vector into a row vector vice versa. For matrices, it swaps rows and columns.\n",
    "- The $i$'th element of vector $\\mathbf{v}$ is denoted $v_i$.\n",
    "\n",
    "### Properties and geometric interpretation of a vector:\n",
    "- The number of elements in a vector is called its **dimension**. This also tells us the vector space it belongs to.\n",
    "    - For example, $\\mathbf{v} \\in \\mathbb{R}^{3}$ is an 3-dimensional vector.\n",
    "- A vector can be thought of as an arrow in n-dimensional space.\n",
    "- The **magnitude** of a vector is its **length** in n-dimensional space. (many distance formulas can be used to compute):\n",
    "    - $L_2$ norm (Euclidian length): $\\Vert\\mathbf{v}\\Vert_2 = \\sqrt{\\Sigma_i w_{i}^{2}}\\quad$ (*physical length* of a vector in n-dim space)\n",
    "    - $L_1$ norm (Manhattan Distance): $\\Vert\\mathbf{v}\\Vert_1 = \\Sigma_i |v_i|\\quad $\n",
    "    - More generally, \n",
    "        - The **p-norm** is $\\Vert v \\Vert_{p} = \\sqrt[p]{(\\sum_i v_i^p)}$\n",
    "        - And the $L_\\infty$ norm, $\\Vert\\mathbf{v}\\Vert_\\infty$, is the $p$-norm where $p=\\infty$\n",
    "    - Generally the $L_2$ norm is implied when referring to vector length. \n",
    "      - Hence $\\Vert\\mathbf{v}\\Vert_2$ can be written more simply as $\\Vert\\mathbf{v}\\Vert$ or occasionally $|\\mathbf{v}|$ (though the latter is ambiguous with the absolute value of a scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bc245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_vec = [ 1 -5  3  2  4] \n",
      "row_vec shape: (1, 5)\n",
      "\n",
      "col_vec =\n",
      " [[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]] \n",
      "col_vec shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a row vector and a column vector, show their shapes\n",
    "row_vec = np.array([[1, -5, 3, 2, 4]])\n",
    "col_vec = np.array([[1], [2], [3], [4]])\n",
    "\n",
    "# Comments show output if you don't use list of lists\n",
    "print(\"row_vec =\", row_vec[0], \"\\nrow_vec shape:\", row_vec.shape)  # [ 1 -5  3  2  4] and (1, 5)\n",
    "print(\"\\ncol_vec =\\n\", col_vec, \"\\ncol_vec shape:\", col_vec.shape)  # [1 2 3 4] and (4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b209b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_vec = [ 1 -5  3  2  4] \n",
      "row_vec shape: (1, 5)\n",
      "\n",
      "transposed_row_vec = [[ 1]\n",
      " [-5]\n",
      " [ 3]\n",
      " [ 2]\n",
      " [ 4]] \n",
      "transposed_row_vec shape: (5, 1) \n",
      "\n",
      "Measures of magnitude:\n",
      "L_1 norm is: 15.0\n",
      "L_2 norm is: 7.4 (most common)\n",
      "L_inf norm is: 5.0 (absolute value of largest element)\n"
     ]
    }
   ],
   "source": [
    "# Transpose row_vec and calculate L1, L2, and L_inf norms\n",
    "from numpy.linalg import norm\n",
    "\n",
    "print(\"row_vec =\", row_vec[0], \"\\nrow_vec shape:\", row_vec.shape)\n",
    "\n",
    "transposed_row_vec = row_vec.T  # now a column vector\n",
    "print(\"\\ntransposed_row_vec =\", transposed_row_vec, \"\\ntransposed_row_vec shape:\", transposed_row_vec.shape, \"\\n\")\n",
    "\n",
    "norm_1 = norm(transposed_row_vec, 1)\n",
    "norm_2 = norm(transposed_row_vec, 2)  # <- L2 norm is default and most common\n",
    "norm_inf = norm(transposed_row_vec, np.inf)\n",
    "\n",
    "print(\"Measures of magnitude:\")\n",
    "print(f\"L_1 norm is: {norm_1:.1f}\")\n",
    "print(f\"L_2 norm is: {norm_2:.1f}\", \"(most common)\")\n",
    "print(f\"L_inf norm is: {norm_inf:.1f}\", \"(absolute value of largest element)\")  # NB: norm_inf = |largest element|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9d66e",
   "metadata": {},
   "source": [
    "## 2. Vector addition, $\\mathbf{v} + \\mathbf{w}$\n",
    "\n",
    "Elementwise addition; if vectors are of of same length (i.e. if $\\mathbf{v}$ and $\\mathbf{w}$ are both in $\\mathbb{R}^n$) then:\n",
    "\n",
    "- **Addition of 2 vectors**: $\\mathbf{u} = \\mathbf{v} + \\mathbf{w}$ is the vector with elements $u_i = v_i + w_i$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43707e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector addition: \n",
      "v + w = [12 14 15]\n"
     ]
    }
   ],
   "source": [
    "# Sum vectors v = [10, 9, 3] and w = [2, 5, 12]\n",
    "v = np.array([[10, 9, 3]])\n",
    "w = np.array([[2, 5, 12]])\n",
    "u = v + w\n",
    "\n",
    "print(\"Vector addition: \\nv + w =\", u[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07b497",
   "metadata": {},
   "source": [
    "## 3. Scalar times vector, $\\alpha\\mathbf{v}$\n",
    "\n",
    "To multiply a vector $\\mathbf{v}$, by a scalar $\\alpha$ (a number in $\\mathbb{R}$), do it \"elementwise\" or \"pairwise\".\n",
    "\n",
    "- **Scalar multiplication of a vector**: $\\mathbf{u} = \\alpha \\mathbf{v}$ is the vector with elements $u_i = \\alpha v_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623eb32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar times vector: \n",
      "alpha * v = [40 36 12]\n"
     ]
    }
   ],
   "source": [
    "# Multiply vector v = [10, 9, 3] by scalar alpha = 4\n",
    "v = np.array([[10, 9, 3]])\n",
    "alpha = 4\n",
    "u = alpha * v\n",
    "\n",
    "print(\"Scalar times vector: \\nalpha * v =\", u[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1095e71b",
   "metadata": {},
   "source": [
    "### 3.1. Linear Combinations\n",
    "\n",
    "- A **linear combination** of set $S$ is defined as $\\Sigma \\alpha_i s_i$\n",
    "    - Here $\\alpha_i$ values are the **coefficients** of $s_i$ values\n",
    "    - Example: Grocery bill total cost is a linear combination of items purchased:\n",
    "        - $\\displaystyle{\\sum c_i n_i}$ ($c_i$ is item cost, $n_i$ is qty. purchased)\n",
    "    \n",
    "### 3.2. Linear Dependence and Independence\n",
    "    \n",
    "- A set is **linearly INdependent** if no object in the set can be written as a lin. combination of the other objects in the set.\n",
    "    - Example: $\\mathbf{v} = [1, 1, 0], \\mathbf{w} = [1, 0, 0]$ and $\\mathbf{u} = [0, 0, 1]$ are <mark>linearly independent. Can you see why?</mark>\n",
    "- Below is an example of a **linearly DEpendent** set. $\\mathbf{x}$ is dependent on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20147719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is a linear combination of v, w, and u. It is linearly dependent on them: \n",
      "x = [-8 -1  4]\n"
     ]
    }
   ],
   "source": [
    "# Writing the vector x = [-8, -1, 4] as a linear combination of 3 vectors, v, w, and u:\n",
    "v = np.array([[0, 3, 2]])\n",
    "w = np.array([[4, 1, 1]])\n",
    "u = np.array([[0, -2, 0]])\n",
    "\n",
    "x = 3 * v - 2 * w + 4 * u\n",
    "print(\"x is a linear combination of v, w, and u. It is linearly dependent on them: \\nx =\", x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2fa7eb",
   "metadata": {},
   "source": [
    "## 4. Vector multiplication (4 approaches)\n",
    "\n",
    "### 4.1. Vector dot (inner) product, $\\mathbf{v} \\cdot \\mathbf{w}$\n",
    "\n",
    "Geometric interpretation: <mark>A measure of how similarly directed two vectors are</mark>\n",
    "\n",
    "- Definition: $\\mathbf{v} \\cdot \\mathbf{w} = \\Sigma_{i=1}^n v_i w_i$\n",
    "    - It's the sum of elementwise products. For $\\mathbf{v}, \\mathbf{w} \\in \\mathbb{R}^n$, \n",
    "- Note also, since $\\mathbf{v}, \\mathbf{w} \\in \\mathbb{R}^n$, transpose to make inner dimensions match. Dot product can hence be rewritten as:\n",
    "    - $\\mathbf{v} \\cdot \\mathbf{w} = \\mathbf{v}^\\mathrm{T}\\mathbf{w}$\n",
    "\n",
    "#### Angle between vectors, $\\theta$\n",
    "\n",
    "- Think of dot product as \"**degree of alignment**\": $\\mathbf{v} \\cdot \\mathbf{w} = \\Vert\\mathbf{v}\\Vert\\:\\Vert\\mathbf{w}\\Vert \\cos \\theta$\n",
    "    - (1,1) and (2,2) are **parallel**; computing the angle gives $\\theta = 0$\n",
    "    - (1,1) and (-1,1) are **orthogonal** (perpendicular) bc $\\theta = \\pi/2$ and $\\mathbf{v} \\cdot \\mathbf{w} = 0$ (no alignment)\n",
    "\n",
    "* Extending on the dot product idea, $\\mathbf{v} \\cdot \\mathbf{w}$, the **angle between two vectors** is $\\theta$. It is as defined by the formula:\n",
    "$$ \\theta = \\arccos \\left({\\frac {\\mathbf{v} \\cdot \\mathbf{w}}{\\left\\|\\mathbf{v}\\right\\|\\left\\|\\mathbf{w} \\right\\|}}\\right) $$\n",
    "\n",
    "#### Recap: Many ways to express a dot product (it's commutative!):\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\n",
    "\\mathbf{v} \\cdot \\mathbf{w} = \\Sigma_{i=1}^n v_i w_i &= \\mathbf{v}^\\mathrm{T}\\mathbf{w} = \\Vert\\mathbf{v}\\Vert\\:\\Vert\\mathbf{w}\\Vert \\cos \\theta \\\\\n",
    "& = \\mathbf{w}^\\mathrm{T}\\mathbf{v} = \\Vert\\mathbf{w}\\Vert\\:\\Vert\\mathbf{v} \\Vert \\cos \\theta = \\mathbf{w} \\cdot \\mathbf{v}\n",
    "\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f895c678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector dot product: v • w = 101\n",
      "Alternative calculation: 101\n",
      "\n",
      "Theta = 0.979924710443726\n"
     ]
    }
   ],
   "source": [
    "from numpy import arccos, dot\n",
    "\n",
    "# Compute the dot (i.e. inner) product of vectors v = [10, 9, 3] and w = [2, 5, 12]\n",
    "v = np.array([[10, 9, 3]])\n",
    "w = np.array([[2, 5, 12]])\n",
    "u = dot(v, w.T)  # w.T to match inner dims, manually need to transpose w to column vector\n",
    "u1 = np.inner(v, w)  # same as dot, but more explicit. Can be used for higher dims. Assumes all inputs column vectors\n",
    "\n",
    "print(\"Vector dot product: v • w =\", u[0][0])\n",
    "print(\"Alternative calculation:\", u1[0][0])\n",
    "\n",
    "# Compute the angle between vectors v and w\n",
    "theta = arccos(u / (norm(v) * norm(w)))  # w.T to match inner dims, norm() default is L2\n",
    "print(\"\\nTheta =\", theta[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821ccb0",
   "metadata": {},
   "source": [
    "### 4.2. Vector outer product, $\\mathbf{v} \\otimes \\mathbf{w}$\n",
    "\n",
    "- Definition: $\\mathbf{v} \\otimes \\mathbf{w}$ is the $m \\times n$ matrix $\\textbf{A}$ obtained by multiplying each element of $\\mathbf{v}$ by each element of $\\mathbf{w}$.\n",
    "    - Unlike with the dot product, here the vectors $\\textbf{v}$ and $\\textbf{w}$ may have different lengths: $\\mathbf{v} \\in \\mathbb{R}^{m\\times 1}$, $ \\mathbf{w} \\in \\mathbb{R}^{n\\times 1}$.\n",
    "    - Elements of the resultant matrix are given by: $ (\\mathbf{v} \\otimes \\mathbf{w} )_{ij}=v_{i}w_{j} $\n",
    "    - The entire matrix is represented as: $$ \\mathbf {v} \\otimes \\mathbf {w} =\\mathbf {A} ={\\begin{bmatrix}v_{1}w_{1}&v_{1}w_{2}&\\dots &v_{1}w_{n}\\\\v_{2}w_{1}&v_{2}w_{2}&\\dots &v_{2}w_{n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\v_{m}w_{1}&v_{m}w_{2}&\\dots &v_{m}w_{n}\\end{bmatrix}} $$\n",
    "\n",
    "- Note also, since $\\mathbf{v}$ and $\\mathbf{w}$ are column vectors ($\\mathbf{v} \\in \\mathbb{R}^{m\\times 1}$, $ \\mathbf{w} \\in \\mathbb{R}^{n\\times 1}$), we can transpose $\\textbf{w}^\\textrm{T}$ (now a row vector, $ \\mathbf{w}^\\mathrm{T} \\in \\mathbb{R}^{1\\times n}$). \n",
    "    - $\\mathbf{v} \\otimes \\mathbf{w}$ is hence equivalent to the matrix multiplication $\\textbf{v}\\textbf{w}^\\textrm{T}$ (since this ensures the inner dimensions ($1$) to match). Example: $$ \\mathbf {v} \\otimes \\mathbf {w} =\\mathbf {v} \\mathbf {w} ^{\\textsf {T}}={\\begin{bmatrix}v_{1}\\\\v_{2}\\\\v_{3}\\\\v_{4}\\end{bmatrix}}{\\begin{bmatrix}w_{1}&w_{2}&w_{3}\\end{bmatrix}}={\\begin{bmatrix}v_{1}w_{1}&v_{1}w_{2}&v_{1}w_{3}\\\\v_{2}w_{1}&v_{2}w_{2}&v_{2}w_{3}\\\\v_{3}w_{1}&v_{3}w_{2}&v_{3}w_{3}\\\\v_{4}w_{1}&v_{4}w_{2}&v_{4}w_{3}\\end{bmatrix}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87aedbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors:\n",
      "v = [10  9  3] \n",
      "w = [ 2  5 12]\n",
      "\n",
      "Vector inner product: v • w = 101\n",
      "\n",
      "Vector outer product: v ⨂ w =\n",
      " [[ 20  50 120]\n",
      " [ 18  45 108]\n",
      " [  6  15  36]]\n",
      "\n",
      "Vector outer product flipped: w ⨂ v =\n",
      " [[ 20  18   6]\n",
      " [ 50  45  15]\n",
      " [120 108  36]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the outer product of same vectors v = [10, 9, 3] and w = [2, 5, 12]\n",
    "v = np.array([[10, 9, 3]])\n",
    "w = np.array([[2, 5, 12]])\n",
    "# w = np.array([[2, 5, 12, 13]])  # <- uncomment to see outer product with different dimensions\n",
    "\n",
    "outer = np.outer(v, w)  # Assumes all inputs column vectors\n",
    "outer2 = np.outer(w, v)  # Assumes all inputs column vectors\n",
    "inner = np.inner(v, w)  # As previous cell\n",
    "\n",
    "print(\"Vectors:\\nv =\", v[0], \"\\nw =\", w[0])\n",
    "print(\"\\nVector inner product: v • w =\", inner[0][0])\n",
    "print(\"\\nVector outer product: v ⨂ w =\\n\", outer)\n",
    "print(\"\\nVector outer product flipped: w ⨂ v =\\n\", outer2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4beca",
   "metadata": {},
   "source": [
    "### 4.3. Vector Hadamard (element-wise) product, $\\mathbf{v}\\odot \\mathbf{w}$:\n",
    "\n",
    "- Definition: Element-wise product, where the vectors **must be of the same dimension**\n",
    "    - This method also works for matrices of the same dimension.\n",
    "    - Output vector/matrix is of the same dimension as the operands.\n",
    "- Notation: $\\mathbf{v}\\odot \\mathbf{w}$ (sometimes $\\mathbf{v}\\circ \\mathbf{w}$)\n",
    "    - Elements of the resultant vector are given by: $ (\\mathbf{v}\\odot \\mathbf{w})_{i} = (\\mathbf{v})_{i}(\\mathbf{w})_{i} $\n",
    "- Example:\n",
    "\n",
    "$$ \\begin{bmatrix}2&3&1\\end{bmatrix} \\odot {\\begin{bmatrix}3&1&4\\end{bmatrix}}={\\begin{bmatrix}2\\times 3&3\\times 1&1\\times 4\\end{bmatrix}}={\\begin{bmatrix}6&3&4\\end{bmatrix}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b7313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Hadamard product:\n",
      "v ⊙ w = [6 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Compute the Hadamard product of vectors v = [2, 3, 1] and w = [3, 1, 4]\n",
    "v = np.array([[2, 3, 1]])\n",
    "w = np.array([[3, 1, 4]])\n",
    "u = np.multiply(v, w)\n",
    "\n",
    "print(\"Vector Hadamard product:\\nv ⊙ w =\", u[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6fca0",
   "metadata": {},
   "source": [
    "### 4.4. Vector cross product, $\\mathbf{v}\\times \\mathbf{w}$\n",
    "\n",
    "Geometric interpretation: The cross product $\\mathbf{v} \\times \\mathbf{w}$ is <mark>a vector perpendicular to both</mark> $\\mathbf{v}$ <mark>and</mark> $\\mathbf{w}$, <mark>whose length equals the area enclosed by the parallelogram created by the two vectors</mark>\n",
    "\n",
    "- Cross product definition: \n",
    "$$\\mathbf{v} \\times \\mathbf{w} = \\Vert \\mathbf{v} \\Vert \\: \\Vert \\mathbf{w} \\Vert\\sin{(\\theta)} \\, \\mathbf{n}$$\n",
    "- Where: \n",
    "    - $\\theta$ can by computed via dot product\n",
    "    - $\\mathbf{n}$ is a unit vector (i.e. length $1$) perpendicular to both $\\mathbf{v}$ and $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab5b4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector cross product:\n",
      "v ⨉ w = [ 0  0 -6]\n"
     ]
    }
   ],
   "source": [
    "# Compute the cross product of v = [0,2,0] and w = [3,0,0]\n",
    "v = np.array([[0, 2, 0]])\n",
    "w = np.array([[3, 0, 0]])\n",
    "u = np.cross(v, w)\n",
    "\n",
    "print(\"Vector cross product:\\nv ⨉ w =\", u[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
